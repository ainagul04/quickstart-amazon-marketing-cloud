{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17e4a41",
   "metadata": {},
   "source": [
    "## Workflow Schedules\n",
    "#### DynamoDB Table - wfm-&lt;teamName&gt;-AMCSchedules-&lt;env&gt;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ee876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "from atsclientslibraries.workflow_schedules import workflowSchedules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbe801",
   "metadata": {},
   "source": [
    "## Global Configs\n",
    "#### Edit the following configuration for your particular AMC Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4856eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Team Name configured in the Data Lake platform\n",
    "# This is the same value passed in the 'data_lake_parameters' team of ddk.json file\n",
    "TEAM_NAME = \"demoteam\"\n",
    "\n",
    "aws_region = 'us-east-1'\n",
    "ENV=\"dev\"\n",
    "customerId = 'democustomer'\n",
    "if aws_region == '':\n",
    "    aws_region = str(boto3.Session().region_name)\n",
    "print(\"Region : \" + aws_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81664b3",
   "metadata": {},
   "source": [
    "## Structure of AMC Workflow Schedule and it's description. They are stored in AMCSchedules DynamoDB Table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e1135",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "  \"customerID\":<ID of Customer. This has to be unique for each customer>,\n",
    "  \"\"Name\":<Name of the Workflow>\"\n",
    "  \"Description\":<Description of the Workflow>,\n",
    "  \"automaticDeploySchedule\":<Set to True if the workflow needs to be automatically deployed from the Library to the Schedule Table, or set to False if not>,\n",
    "  \"ScheduleExpression\":<Schedule expression of the Workflow. See below for more details.>,\n",
    "  \"State\":<ENABLED or DISABLED; If set to DISABLED, the schedule will not be executed>,\n",
    "  \"Input\": {\n",
    "      \"payload\": {\n",
    "          \"timeWindowEnd\":<End Date of the report for e.g today(-1) will set the end time to be 1 day back form current time>,\n",
    "          \"timeWindowStart\":Start date of the report for e.g today(-15) will set the start time to be 15 days back from current time>,\n",
    "          \"timeWindowType\":<EXPLICIT>,\n",
    "          \"workflow_executed_date\":<e.g now()>,\n",
    "          \"workflowId\":<ID of the workflow. This has to be unique for each workflow>\n",
    "      }\n",
    "  }   \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9f2d9",
   "metadata": {},
   "source": [
    "## Schedule Expressions\n",
    "\n",
    "```\n",
    "Two Types of Schedule Expressions:\n",
    "1) Cron\n",
    "\n",
    "Cron Expression Format: cron(Minutes Hours Day-of-month Month Day-of-week Year)\n",
    "Use Cron Expression if a workflow needs to be scheduled at a specific day and time for e.g cron(15 10 * * ? *) means the workflow will be scheduled for 10:15(UTC) Everyday or cron(0 9 ? * 2#1 *) means the workflow will be scheduled for 9:00 AM on the first Monday of each month. For details refer https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html\n",
    "\n",
    "2) Custom (Recommended)\n",
    "Custom Expressin Format: custom({H/D/W/M} {Day-of-the-week/month} {Hour-of-the-Day}), where H=Hourly, D=Daily, W=Weekly and M=Monthly.\n",
    "Use custom Expression if there is no hard requirement for a workflow to run at specific time. For e.g, custom(D * 14) means workflow will be scheduled to run Daily at sometime between 14:00 and 14:59 UTC, custom(W 2 8) means it will be scheduled to run Weekly on every 2nd day of the week at sometime between 08:00 and 08:59 UTC, custom(H * *) will schedule it to run every hour.\n",
    "This is the recommended approach as it utilizes less resources.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6f11a",
   "metadata": {},
   "source": [
    "### Workflow Schedules are automatically loaded from the workflow library if the automaticDeploySchedule is set True. This Notebook can help add new custom workflow schedules or update any existing ones such as change the schedule time. Below is a sample Workflow Schedule record. Use this sample to create or update Workflows Schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow record\n",
    "workflow =  {\n",
    "  \"automaticDeploySchedule\": False,\n",
    "  \"customerId\": customerId,\n",
    "  \"Description\": \"Runs the exposure_group_analysisn workflow at 11:00 GMT / 9:00am EST daily. \",\n",
    "  \"Input\": {\n",
    "    \"payload\": {\n",
    "      \"timeWindowEnd\": \"today(-2)\",\n",
    "      \"timeWindowStart\": \"today(-3)\",\n",
    "      \"timeWindowType\": \"EXPLICIT\",\n",
    "      \"workflow_executed_date\": \"now()\",\n",
    "      \"workflowId\": \"exposure_group_analysis_v1\"\n",
    "    }\n",
    "  },\n",
    "  \"Name\": f'wfm-{customerId}-exposure_group_analysis_v1',\n",
    "  \"ScheduleExpression\": \"custom(D * 11)\",\n",
    "  \"State\": \"ENABLED\"\n",
    "}\n",
    "\n",
    "print(json.dumps(workflow, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25423e3f",
   "metadata": {},
   "source": [
    "### Create/Update an AMC Workflow Schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb_resp_wr = workflowSchedules.set_workflow_schedule(workflow_details=workflow, TEAM_NAME=TEAM_NAME, ENV=ENV)\n",
    "dynamodb_resp_wr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a9c5c",
   "metadata": {},
   "source": [
    "### Retrieve AMC Workflow Schedules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "df = workflowSchedules.get_workflow_schedule(TEAM_NAME=TEAM_NAME, ENV=ENV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c79f21",
   "metadata": {},
   "source": [
    "## Delete a Workflow Schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c51a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_name = f'wfm-{customerId}-exposure_group_analysis_v1'\n",
    "dynamodb_resp_dl = workflowSchedules.delete_workflow_schedule(customerId=customerId, workflowName=wf_name, TEAM_NAME=TEAM_NAME, ENV=ENV)\n",
    "dynamodb_resp_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1978709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
