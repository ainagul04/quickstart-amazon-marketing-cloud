{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63dd0be9",
   "metadata": {},
   "source": [
    "\n",
    "# Getting Started with the AMC Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e49e7",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd37af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "from client_manager_microservices.tps.atsclientslibraries.clientmgr import customer\n",
    "from datalake_hydration_microservices.wfm.atsclientslibraries.workflows import workflows\n",
    "from datalake_hydration_microservices.wfm.atsclientslibraries.workflow_invoke import workflowInvoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863f231",
   "metadata": {},
   "source": [
    "#### Define Global Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = \"dev\" # Change to your Default Environment\n",
    "\n",
    "## The Team Name configured in the Data Lake platform\n",
    "# This is the same value passed in the 'data_pipeline_parameters' team of ddk.json file\n",
    "TEAM_NAME = \"<INSERT TEAM NAME>\" \n",
    "\n",
    "## The Dataset Name configured in the Data Lake platform\n",
    "# This is the same value passed in the 'data_pipeline_parameters' dataset of ddk.json file\n",
    "amc_dataset_name = \"<INSERT DATASET NAME>\" \n",
    "\n",
    "# The AMC Instance information can be found on your AMC UI page\n",
    "amc_api_endpoint = \"<ENTER AMC API ENDPOINT URL>\"\n",
    "\n",
    "amc_s3_bucket_name = \"<ENTER AMC S3 BUCKET NAME>\"\n",
    "\n",
    "amc_data_upload_acct = \"<ENTER ACCOUNT ID>\"\n",
    "\n",
    "## The AMC Instance AWS region (also in the API Endpoint URL)\n",
    "# This may differ from your solution deployment region\n",
    "amc_instance_region = 'us-east-1'\n",
    "\n",
    "#OPTIONAL: Change to your desired Customer ID (keep less than 25 characters) \n",
    "customer_id = \"testdemocustomer\"\n",
    "\n",
    "if amc_instance_region == '':\n",
    "    amc_instance_region = str(boto3.Session().region_name)\n",
    "print(\"Region : \" + amc_instance_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad4a8f",
   "metadata": {},
   "source": [
    "#### Step 1: Onboard A New Client\n",
    "\n",
    "Tenant Provisioning Service (TPS) is used for onboarding clients for each team space. Each Client should be configured in the same AWS Region as the AMC Instance. Each client is defined by:\n",
    "\n",
    "1. An AMC Instance\n",
    "2. Corresponding profiles ids which are grouped for this customer according the advertiserids used for setting up the AMC instance\n",
    "\n",
    "The following notebook cells will define your client configuration, onboard your client, and create the AMC S3 Bucket for that client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab41f6c",
   "metadata": {},
   "source": [
    "##### Define your Client Configuration\n",
    "\n",
    "Run the below cell to setup and verify the client configuration. \n",
    "\n",
    "Refer to the `client_manager_microservices/client_manager_adminstrator_sample` notebook for more information on the configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_details = {\n",
    "    \"customer_id\": customer_id,\n",
    "    \"customer_name\":\"DemoCustomer\",     #OPTIONAL: Change to your desired Customer Name\n",
    "    \"customer_type\": \"ENDEMIC\",         #Can Be <ENDEMIC or NON-ENDEMIC>\n",
    "    \"region\":amc_instance_region,\n",
    "    \"amc\":{\n",
    "        \"amc_dataset_name\":amc_dataset_name,\n",
    "        \"endpoint_url\": amc_api_endpoint,\n",
    "        \"aws_orange_account_id\": amc_data_upload_acct,\n",
    "        \"bucket_name\": amc_s3_bucket_name\n",
    "    }\n",
    "}\n",
    "\n",
    "print(json.dumps(customer_details, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90624e",
   "metadata": {},
   "source": [
    "##### Submit Your Client Configuration to Create The AMC S3 Bucket\n",
    "\n",
    "Running the cells below will start the process of onboarding your client and creating the AMC S3 Bucket for your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71bb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb_resp_wr = customer.set_customers_config(customer_details=customer_details, TEAM_NAME=TEAM_NAME, ENV=ENV)\n",
    "dynamodb_resp_wr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4208a",
   "metadata": {},
   "source": [
    "_Wait a few minutes for the AMC S3 Bucket to be deployed BEFORE moving to Step #2._\n",
    "\n",
    "_You Can Verify the Status by going to AWS Step Functions and waiting until the state machine named tps-&lt;TeamName&gt;-initialize-amc has 1 Succeeded Execution Status._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc5dd7",
   "metadata": {},
   "source": [
    "#### Step 2: Define An AMC Workflow Query and Set An AMC Workflow Record. \n",
    "\n",
    "Workflow Manager (WFM) Service is used to manage and schedule AMC workflows. The following notebook cells with walkthrough the process of creating an AMC workflow query and creating an AMC Workflow record for the specified query.\n",
    "\n",
    "The query used here is the Time To Conversion Query from the Interactive Query Library (IQL) in the AMC UI.\n",
    "\n",
    "The query finds out how long it takes for your customers to convert after last seeing your ad. You can use this information to adjust the duration of campaign and promotion to maximize sales. In our amazon_attributed_events_by_conversion_time and amazon_attributed_events_by_traffic_time tables, we report up to 14 days after the customersâ€™ last exposure to your ad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b65bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "amc_query = \"\"\"\n",
    "SELECT\n",
    "      advertiser,\n",
    "      campaign,\n",
    "        ( \n",
    "            CASE WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 60 THEN\n",
    "                '1 | < 1 MIN'\n",
    "                WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 600 THEN\n",
    "                '2 | 1 - 10 MIN'\n",
    "                WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 1800 THEN\n",
    "                '3 | 10 - 30 MIN'\n",
    "                WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 3600 THEN\n",
    "                '4 | 30 - 60 MIN'\n",
    "                WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 7200 THEN\n",
    "                '5 | 1 - 2 HRS'\n",
    "                WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 43200 THEN\n",
    "                '6 | 2 - 12 HRS'\n",
    "                WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 86400 THEN\n",
    "                '7 | 12 - 24 HRS'\n",
    "                WHEN SECONDS_BETWEEN (impression_dt,\n",
    "                    conversion_event_dt) <= 604800 THEN\n",
    "                '8 | 1 - 7 DAYS'\n",
    "            ELSE\n",
    "                '9 | 7+ DAYS'\n",
    "END\n",
    ") AS time_to_conversion,\n",
    "        SUM(purchases) AS purchases,\n",
    "        SUM(total_purchases) AS total_brand_purchases\n",
    "FROM\n",
    "    amazon_attributed_events_by_conversion_time\n",
    "    \n",
    "GROUP BY 1,2,3\n",
    "\"\"\"\n",
    "\n",
    "print (amc_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d8633",
   "metadata": {},
   "source": [
    "__NOTE__: This is just one example of a workflow query you can run on your AMC Instance. Refer to the Interactive Query Library (IQL) in the AMC UI for a list of other queries for different use cases. Queries can also be customized for you unique use case as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44171c",
   "metadata": {},
   "source": [
    "##### Create The AMC Workflow Record\n",
    "\n",
    "Run the below cell to setup and verify the workflow configuration (default configuration values are already populated). \n",
    "\n",
    "Refer to the `datalake_hydration_microservices/workflows_wfm_sample` notebook for more information on the workflow configuration parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efce523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow record\n",
    "workflow = {\n",
    "  \"customerId\": customer_id,\n",
    "  \"defaultSchedule\": {\n",
    "    \"automaticDeploySchedule\": False,\n",
    "    \"Description\": \"Runs the time_to_conversion workflow. \",\n",
    "    \"Input\": {\n",
    "      \"payload\": {\n",
    "        \"timeWindowEnd\": \"today(-1)\",\n",
    "        \"timeWindowStart\": \"today(-91)\",\n",
    "        \"timeWindowType\": \"EXPLICIT\",\n",
    "        \"workflow_executed_date\": \"now()\"\n",
    "      }\n",
    "    },\n",
    "    \"Name\": \"time_to_conversion\",\n",
    "  },\n",
    "  \"filteredMetricsDiscriminatorColumn\": \"filtered\",\n",
    "  \"sqlQuery\": amc_query,\n",
    "  \"version\": 1,\n",
    "  \"workflowId\": \"time_to_conversion_v1\",\n",
    "  \"workflowMetaData\": {\n",
    "    \"automaticDeployWorkflow\": True,\n",
    "    \"endemicType\": \"ENDEMIC\"\n",
    "  },\n",
    "  \"workflowType\": \"ENDEMIC|NON-ENDEMIC\"\n",
    "}\n",
    "\n",
    "print(json.dumps(workflow, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb_resp_wr = workflows.set_workflow_record(workflow_details=workflow, TEAM_NAME=TEAM_NAME, ENV=ENV)\n",
    "dynamodb_resp_wr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e44df8",
   "metadata": {},
   "source": [
    "#### Step 3: Invoke the AMC Workflow to be Executed Ad Hoc\n",
    "\n",
    "Run the below cell to set up your workflow exeuction configuration (default configuration values are already populated). \n",
    "\n",
    "Refer to the `datalake_hydration_microservices/workflows_invoke_wfm_sample` notebook for more information on the workflow exeuction configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84123851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow record\n",
    "workflow =  {\n",
    "  \"customerId\": customer_id,\n",
    "  \"Description\": \"Runs the time_to_conversion workflow looking back to 90 days prior\",\n",
    "  \"Input\": {\n",
    "    \"payload\": {\n",
    "      \"timeWindowEnd\": \"today(-1)\",\n",
    "      \"timeWindowStart\": \"today(-91)\",\n",
    "      \"timeWindowType\": \"EXPLICIT\",\n",
    "      \"workflow_executed_date\": \"now()\",\n",
    "      \"workflowId\": \"time_to_conversion_v1\"\n",
    "    }\n",
    "  },\n",
    "  \"Name\": f'wfm-{customer_id}-time_to_conversion'\n",
    "}\n",
    "\n",
    "print(json.dumps(workflow, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = workflowInvoke.invoke_workflow(workflow, TEAM_NAME, ENV)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57d1e3",
   "metadata": {},
   "source": [
    "__NOTE__: In this example we are invoking the time_to_conversion workflow to be run once. Workflows can also be set up to run on pre-defined schedules custom to your use case. Refer to the `workflowLibrary_wfm_sample` and `workflowSchedules_wfm_sample` notebooks for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29beab",
   "metadata": {},
   "source": [
    "#### Your workflow is now being processed and executed. \n",
    "Once the workflow has run, data will be uploaded to your AMC S3 Bucket with the results of the workflow query and processed through the data lake. \n",
    "\n",
    "- Continue exploring the notebooks in the `client_manager_microservices` folder for further documentation on how to onboard new clients\n",
    "\n",
    "- Continue exploring the notebooks in the `datalake_hydration_microservices` folder for further documentation on how to schedule and manage your workflows and submit multiple workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99760076",
   "metadata": {},
   "source": [
    "### Optional : Data Visualization Using Workflow Query Results\n",
    "\n",
    "Before you begin setting up data visualizations please wait until the workflow query has been executed and data has been populated in S3 and processed by the data lake. This can take up to 30 minutes for data to be populated on S3 and processed through the data lake.\n",
    "\n",
    "Verify that there is data for your query result in the S3 Path: \n",
    "\n",
    "    amc-{ENV}-{aws_region}-{account_id}-stage/post-stage/{TEAM_NAME}/\n",
    "\n",
    "Once you have your query results, run the below cell to visualize the data you have gathered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73709ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data Visualization Python Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "from datetime import datetime\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in parameters for workflow_id and the solution deployment_region \n",
    "# The deployment_region may differ from the amc_instance_region set earlier in the notebook\n",
    "workflow_id = \"time_to_conversion_v1\"\n",
    "deployment_region = \"<ENTER SOLUTION DEPLOYMENT REGION>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a836c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "bucket_name = f\"amc-{ENV}-{deployment_region}-{account_id}-stage\"\n",
    "\n",
    "d = datetime.today()\n",
    "month = '{:02d}'.format(d.month)\n",
    "year = '{:04d}'.format(d.year)\n",
    "\n",
    "#Retrieving S3 Key for Processed Data\n",
    "s3_prefix = \"post-stage/{}/{}/{}_{}_adhoc/customer_hash={}/export_year={}/export_month={}\".format(TEAM_NAME, amc_dataset_name, customer_id, workflow_id, customer_id, year, month)\n",
    "response = s3_client.list_objects(Bucket=bucket_name, Prefix= s3_prefix)\n",
    "s3_key = \"/\".join(response[\"Contents\"][0][\"Key\"].split(\"/\")[:-1])\n",
    "\n",
    "\n",
    "# CONFIRM THIS IS THE CORRECT S3_PATH FOR YOUR PROCESSED DATA\n",
    "s3_path = f\"s3://{bucket_name}/{s3_key}\"\n",
    "s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from the processed data in Amazon S3\n",
    "df = wr.s3.read_parquet(s3_path, dataset=True)\n",
    "\n",
    "#View Data Returned From Query Results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum Purchases by Time To Conversion Groups\n",
    "purchases_df = df.groupby(df[\"time_to_conversion\"], as_index=False, sort=True, group_keys=True)[\"time_to_conversion\",\"purchases\"].sum()\n",
    "purchases_df[\"Type\"]= \"Purchases\"\n",
    "\n",
    "# Sum  Total_Brand_Purchases by Time To Conversion Groups\n",
    "total_purchases_df = df.groupby(df[\"time_to_conversion\"], as_index=False, sort=True, group_keys=True)[  \"total_brand_purchases\"].sum()\n",
    "total_purchases_df[\"Type\"]= \"Total Brand Purchases\"\n",
    "\n",
    "\n",
    "# Join 2 DataFrames Together\n",
    "total_purchases_df.rename(columns={'total_brand_purchases': 'purchases'}, inplace=True)\n",
    "p_df = purchases_df.append(total_purchases_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# Re-Format Time To Conversion\n",
    "p_df[['time_to_conversion','Time To Conversion']] = p_df['time_to_conversion'].str.split(\"|\", expand=True)\n",
    "p_df = p_df.drop('time_to_conversion', 1)\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81929eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Figure Size\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Create Bar Plot\n",
    "ax = sns.barplot(x = \"Time To Conversion\",\n",
    "            y = \"purchases\",\n",
    "            hue = \"Type\",\n",
    "            palette = \"coolwarm\",\n",
    "            data = p_df)\n",
    "\n",
    "# Change Bar Width\n",
    "width_scale = 0.9\n",
    "for bar in ax.containers[0]:\n",
    "    bar.set_width(bar.get_width()* width_scale)\n",
    "for bar in ax.containers[1]: \n",
    "    bar.set_width(bar.get_width()* width_scale)\n",
    "\n",
    "    \n",
    "# Format Y Axis\n",
    "def currency(x, pos):\n",
    "    \"\"\"The two args are the value and tick position\"\"\"\n",
    "    if x >= 1e6:\n",
    "        s = '${:1.1f}M'.format(x*1e-6)\n",
    "    else:\n",
    "        s = '${:1.1f}K'.format(x*1e-3)\n",
    "    return s\n",
    "\n",
    "ax.yaxis.set_major_formatter(currency)\n",
    "\n",
    "# Label Axes\n",
    "plt.ylabel(\"Purchases\", fontsize=16)\n",
    "plt.xlabel(\"Time To Conversion\", fontsize=16)\n",
    "plt.yticks(rotation=25)\n",
    "\n",
    "\n",
    "# Add Values to Bar Chart\n",
    "for p in ax.patches:\n",
    "        ax.annotate('${:,.0f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()),ha='center', va='bottom',color= 'black')\n",
    "\n",
    "\n",
    "# Add Title\n",
    "plt.title(\"Purchases By time To Conversion\", fontsize = 24)\n",
    "\n",
    "# Resize Plot Legend\n",
    "plt.legend(loc=1, prop={'size': 12})\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a7387",
   "metadata": {},
   "source": [
    "#### Data Visualization Using QuickSight Dashboards\n",
    "\n",
    "If you require more advanced and customizable data visualizations consider using Amazon QuickSight as your BI Tool.  With Amazon QuickSight you can perform advanced analytics, gather machine learning (ML) insights and embed interactive visualizations and dashboards with natural language query capabilities. Refer to the AMC QuickStart FAQ to find more information on how to set up your own Amazon QuickSight Dashboards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
